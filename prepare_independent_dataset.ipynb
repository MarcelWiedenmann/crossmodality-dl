{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation of the independent data set used for external validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import serial H&E images into workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "from pathlib import Path\n",
    "from datasets.independent import import_images\n",
    "\n",
    "\n",
    "source_dir = c.serial_he_source_dir\n",
    "image_names = list(c.serial2terminal.keys())\n",
    "target_dir = c.scratch_dir / \"serial_he\"\n",
    "\n",
    "\n",
    "import_images(source_dir, target_dir, image_names=image_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially register serial sections with terminal counterparts\n",
    "The registration process generates a lot of textual output which tends to overwhelm Jupyter when run directly in the notebook, so do it in an external script instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "\n",
    "\n",
    "for serial_img_name in c.serial2terminal.keys():\n",
    "    !source activate torch && echo Registering $serial_img_name && python run_registration.py $serial_img_name > /dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read registered H&E channels at full scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "import numpy as np\n",
    "import utils\n",
    "from logging import info\n",
    "from skimage.util import img_as_float32\n",
    "from tifffile import imread\n",
    "\n",
    "\n",
    "\n",
    "source_dir = c.scratch_dir / \"serial_he_registered\"\n",
    "target_dir = c.scratch_dir / \"serial_he_preprocessed\" / \"level_0\"\n",
    "\n",
    "\n",
    "image_paths = utils.list_files(source_dir, file_pattern=\"*/*.tif\")\n",
    "target_dir.mkdir(parents=True)\n",
    "for image_path in image_paths:\n",
    "    save_path = target_dir / (image_path.name + \".npy\")\n",
    "    info(f\"Reading H&E channels from image {image_path} and saving them to {save_path}.\")\n",
    "    image = imread(image_path)\n",
    "    image = np.moveaxis(image, -1, 0)  # Channels last to channels first.\n",
    "    image = img_as_float32(image)\n",
    "    info(f\"Shape and data type of the channels: {image.shape}, {image.dtype}.\")\n",
    "    np.save(save_path, image)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate multi-scale versions of registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "import numpy as np\n",
    "import utils\n",
    "from logging import info\n",
    "from skimage.transform import pyramid_reduce\n",
    "\n",
    "\n",
    "source_dir = c.scratch_dir / \"serial_he_preprocessed\" / \"level_0\"\n",
    "target_dir = c.scratch_dir / \"serial_he_preprocessed\"\n",
    "pyramid_levels = [2, 3]\n",
    "\n",
    "\n",
    "terminal_imgs_dir = c.scratch_dir / \"dataset_208_preprocessed\" / \"he\"\n",
    "\n",
    "image_paths = utils.list_files(source_dir, file_extension=\".npy\")\n",
    "for image_path in image_paths:\n",
    "    last_level = 0\n",
    "    last_image = np.load(image_path)\n",
    "    for level in pyramid_levels:\n",
    "        level_dir = target_dir / f\"level_{level}\"\n",
    "        level_dir.mkdir(exist_ok=True)\n",
    "        save_path = level_dir / image_path.name\n",
    "        info(f\"Downsampling image {image_path.name} to level {level} and saving it to {save_path}.\")\n",
    "        image = pyramid_reduce(np.moveaxis(last_image, 0, -1), downscale=2*(level-last_level), multichannel=True)\n",
    "        image = np.moveaxis(image, -1, 0)\n",
    "        # We may need to manually crop the individual levels of the pyramid (by at most 1 pixel) since pyramid_reduce\n",
    "        # seems to use a different rounding mechanism for the shape dimensions than was used in the terminal images.\n",
    "        terminal_img_path = terminal_imgs_dir / f\"level_{level}\" /  (c.serial2terminal[image_path.stem] + \".npy\")\n",
    "        *_, terminal_size_y, terminal_size_x = np.load(terminal_img_path, mmap_mode=\"r\").shape\n",
    "        image = image[..., :terminal_size_y, :terminal_size_x]\n",
    "        info(f\"Shape of the level: {image.shape}.\")\n",
    "        np.save(save_path, image)\n",
    "        last_level = level\n",
    "        last_image = image\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiling #1\n",
    "For segmentation using the model from Schmitz et al. (2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the H&E images at the different scale levels into tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "from preprocessing import tile_images\n",
    "\n",
    "\n",
    "source_dir = c.scratch_dir / \"serial_he_preprocessed\"\n",
    "pyramid_levels = [0, 2, 3]\n",
    "tile_shapes = [(512, 512), (512, 512), (512, 512)]\n",
    "stride = (512, 512)\n",
    "target_dir = c.scratch_dir / \"serial_he_tiled\"\n",
    "\n",
    "\n",
    "for level, tile_shape in zip(pyramid_levels, tile_shapes):\n",
    "    level_dir = target_dir / f\"level_{level}\"\n",
    "    level_dir.mkdir(parents=True, exist_ok=True)\n",
    "    overlap = (tile_shape[0] - stride[0]) // 2, (tile_shape[1] - stride[1]) // 2\n",
    "    tiling_dir = (\n",
    "        level_dir / f\"shape_{stride[0]}_{stride[1]}_overlap_{overlap[0]}_{overlap[1]}\"\n",
    "    )\n",
    "\n",
    "    anchor_y = stride[0] // 2 ** (level + 1)\n",
    "    anchor_x = stride[1] // 2 ** (level + 1)\n",
    "    stride_y = stride[0] // 2**level\n",
    "    stride_x = stride[1] // 2**level\n",
    "\n",
    "    tile_images(\n",
    "        source_dir / f\"level_{level}\",\n",
    "        tiling_dir,\n",
    "        tile_shape,\n",
    "        (anchor_y, anchor_x),\n",
    "        (stride_y, stride_x),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index structures for guidance of tile sampling at training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lookup tables for tissue foreground-to-background ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "import numpy as np\n",
    "from datasets.independent import extract_tissue_fg\n",
    "from preprocessing import compute_tile_statistics\n",
    "\n",
    "\n",
    "tilings_dir = (\n",
    "    c.scratch_dir / \"serial_he_tiled\" / \"level_0\" / \"shape_512_512_overlap_0_0\"\n",
    ")\n",
    "\n",
    "\n",
    "def compute_tissue_fg_ratio(tile: np.ndarray) -> float:\n",
    "    assert np.issubdtype(tile.dtype, np.floating)\n",
    "    tissue_mask = extract_tissue_fg(tile)\n",
    "    return tissue_mask.sum() / float(tissue_mask.size)\n",
    "\n",
    "\n",
    "compute_tile_statistics(tilings_dir, \"tissue_fg_ratios\", compute_tissue_fg_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiling #2\n",
    "For stain transfer (training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "from preprocessing import tile_images\n",
    "\n",
    "\n",
    "source_dir = c.scratch_dir / \"serial_he_preprocessed\"\n",
    "pyramid_levels = [0]\n",
    "tile_shapes = [(256, 256), (256, 256), (256, 256)]\n",
    "stride = (256, 256)\n",
    "target_dir = c.scratch_dir / \"serial_he_tiled\"\n",
    "\n",
    "\n",
    "for level, tile_shape in zip(pyramid_levels, tile_shapes):\n",
    "    level_dir = target_dir / f\"level_{level}\"\n",
    "    level_dir.mkdir(parents=True, exist_ok=True)\n",
    "    overlap = (tile_shape[0] - stride[0]) // 2, (tile_shape[1] - stride[1]) // 2\n",
    "    tiling_dir = (\n",
    "        level_dir / f\"shape_{stride[0]}_{stride[1]}_overlap_{overlap[0]}_{overlap[1]}\"\n",
    "    )\n",
    "\n",
    "    anchor_y = stride[0] // 2 ** (level + 1)\n",
    "    anchor_x = stride[1] // 2 ** (level + 1)\n",
    "    stride_y = stride[0] // 2**level\n",
    "    stride_x = stride[1] // 2**level\n",
    "\n",
    "    tile_images(\n",
    "        source_dir / f\"level_{level}\",\n",
    "        tiling_dir,\n",
    "        tile_shape,\n",
    "        (anchor_y, anchor_x),\n",
    "        (stride_y, stride_x),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "import numpy as np\n",
    "from datasets.independent import extract_tissue_fg\n",
    "from preprocessing import compute_tile_statistics\n",
    "\n",
    "\n",
    "tilings_dir = (\n",
    "    c.scratch_dir / \"serial_he_tiled\" / \"level_0\" / \"shape_256_256_overlap_0_0\"\n",
    ")\n",
    "\n",
    "\n",
    "def compute_tissue_fg_ratio(tile: np.ndarray) -> float:\n",
    "    assert np.issubdtype(tile.dtype, np.floating)\n",
    "    tissue_mask = extract_tissue_fg(tile)\n",
    "    return tissue_mask.sum() / float(tissue_mask.size)\n",
    "\n",
    "\n",
    "compute_tile_statistics(tilings_dir, \"tissue_fg_ratios\", compute_tissue_fg_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiling #3\n",
    "For stain transfer (inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as c\n",
    "from preprocessing import tile_images\n",
    "\n",
    "\n",
    "source_dir = c.scratch_dir / \"serial_he_preprocessed\"\n",
    "pyramid_levels = [0]\n",
    "tile_shapes = [(2048, 2048), (2048, 2048), (2048, 2048)]\n",
    "stride = (512, 512)\n",
    "target_dir = c.scratch_dir / \"serial_he_tiled\"\n",
    "\n",
    "\n",
    "for level, tile_shape in zip(pyramid_levels, tile_shapes):\n",
    "    level_dir = target_dir / f\"level_{level}\"\n",
    "    level_dir.mkdir(parents=True, exist_ok=True)\n",
    "    overlap = (tile_shape[0] - stride[0]) // 2, (tile_shape[1] - stride[1]) // 2\n",
    "    tiling_dir = (\n",
    "        level_dir / f\"shape_{stride[0]}_{stride[1]}_overlap_{overlap[0]}_{overlap[1]}\"\n",
    "    )\n",
    "\n",
    "    anchor_y = stride[0] // 2 ** (level + 1)\n",
    "    anchor_x = stride[1] // 2 ** (level + 1)\n",
    "    stride_y = stride[0] // 2**level\n",
    "    stride_x = stride[1] // 2**level\n",
    "\n",
    "    tile_images(\n",
    "        source_dir / f\"level_{level}\",\n",
    "        tiling_dir,\n",
    "        tile_shape,\n",
    "        (anchor_y, anchor_x),\n",
    "        (stride_y, stride_x),\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
